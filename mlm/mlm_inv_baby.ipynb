{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/guest/Desktop/projects/third-experiments/SDA_experiments/mlm', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages', '/home/guest/Desktop/projects/third-experiments/SDA_experiments/modules', '/tmp/tmpkxj2dfrg']\n"
     ]
    }
   ],
   "source": [
    "from setup import setup_src_path\n",
    "print(setup_src_path())\n",
    "import data.processed as processed\n",
    "import config.config as config\n",
    "import utils.setup as setup\n",
    "import utils.functions as fn\n",
    "from importlib import reload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset with Unlabeled and Dev Splits:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence'],\n",
      "        num_rows: 1350\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['sentence'],\n",
      "        num_rows: 150\n",
      "    })\n",
      "})\n",
      "\n",
      "Test Target Dataset:\n",
      "Dataset({\n",
      "    features: ['sentence', 'label'],\n",
      "    num_rows: 400\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk,concatenate_datasets\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "adapter_name=\"mlm_inv_baby\"\n",
    "\n",
    "# Define paths to the CSV files\n",
    "unlabeled_target_data_path = \"../../datasets/sa/books_baby/target_unlabelled.csv\"\n",
    "dev_target_data_path = \"../../datasets/sa/books_baby/dev_target.csv\"\n",
    "test_target_data_path = \"../../datasets/sa/books_baby/test_target.csv\"\n",
    "\n",
    "# Read the CSV files into DataFrames\n",
    "df_unlabeled_target = pd.read_csv(unlabeled_target_data_path)\n",
    "df_dev_target = pd.read_csv(dev_target_data_path)\n",
    "df_test_target = pd.read_csv(test_target_data_path)\n",
    "\n",
    "# Convert the DataFrames to dictionaries\n",
    "data_dict_unlabeled_target = df_unlabeled_target.to_dict(orient=\"records\")\n",
    "data_dict_dev_target = df_dev_target.to_dict(orient=\"records\")\n",
    "data_dict_test_target = df_test_target.to_dict(orient=\"records\")\n",
    "\n",
    "# Create Dataset objects from the dictionaries\n",
    "dataset_unlabeled_target = Dataset.from_dict({\n",
    "    \"sentence\": [record[\"sentence\"] for record in data_dict_unlabeled_target],\n",
    "    \n",
    "})\n",
    "\n",
    "dataset_dev_target = Dataset.from_dict({\n",
    "    \"sentence\": [record[\"sentence\"] for record in data_dict_dev_target],\n",
    "})\n",
    "\n",
    "dataset_test_target = Dataset.from_dict({\n",
    "    \"sentence\": [record[\"sentence\"] for record in data_dict_test_target],\n",
    "    \"label\": [record[\"label\"] for record in data_dict_test_target]\n",
    "})\n",
    "\n",
    "# Combine the unlabeled_target and dev_target datasets into a DatasetDict for training\n",
    "dataset_train = DatasetDict({\n",
    "    \"train\": dataset_unlabeled_target,\n",
    "    \"dev\": dataset_dev_target\n",
    "})\n",
    "\n",
    "# Print the datasets to verify\n",
    "print(\"Training Dataset with Unlabeled and Dev Splits:\")\n",
    "print(dataset_train)\n",
    "\n",
    "print(\"\\nTest Target Dataset:\")\n",
    "print(dataset_test_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '\"i was very disppointed in this product . i found it great that the containers would easily stack in the freezer , but this was the only good quality . i had to throw out all of my containers because they leaked and the plastic was obviously leaching . you could smell the plastic in the milk . i \\'m not going to expose my baby to extra chemicals , especially when her liver is n\\'t developed enough to fully detoxify them . i really wanted to love this product , but leaching plastic that leaks is not an acceptable option\"'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(config)\n",
    "\n",
    "\n",
    "train_target = dataset_train\n",
    "test_target = dataset_test_target\n",
    "train_target['train'][1]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 109514298 || all params: 109514298 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "from adapters import AutoAdapterModel,init\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForMaskedLM\n",
    "\n",
    "mdlcfg = AutoConfig.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    " \n",
    ")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    ")\n",
    "init(model)\n",
    "reload(fn)\n",
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "mlm_inv_baby             bottleneck        7,387,776       6.785       1       1\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                               108,891,648     100.000               0\n",
      "================================================================================\n",
      "trainable params: 7979904 || all params: 116902074 || trainable%: 6.82614407679371\n"
     ]
    }
   ],
   "source": [
    "from adapters import ConfigUnion, LoRAConfig, PrefixTuningConfig, SeqBnConfig,SeqBnInvConfig,AdapterConfig,LoRAConfig\n",
    "\n",
    "\n",
    "adapter_config = SeqBnInvConfig(reduction_factor=2)\n",
    "\n",
    "model.add_adapter(adapter_name, config=adapter_config)\n",
    "\n",
    "model.train_adapter([adapter_name])\n",
    "model.active_adapters = adapter_name\n",
    "print(model.adapter_summary())\n",
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd82d8ff7913415882014ffd00cf9e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84b07877f4748d7b0069ecbcab56785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 1350\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "reload(processed)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.Config.TOKENIZER_NAME)\n",
    "\n",
    "tokenized_dataset= processed.tokenize_dataset(train_target,tokenizer)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 128\n",
    "# Slicing produces a list of lists for each feature\n",
    "tokenized_samples = tokenized_dataset['train'][444:470]\n",
    "\n",
    "results = fn.group_texts(tokenized_samples, chunk_size)\n",
    "for chunk in results[\"labels\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ede6410129e40b0971cf020e0b5e84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870b2a4133044e229a7129fb5d70eae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 1405\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 161\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we group texts and chunk them\n",
    "lm_datasets = tokenized_dataset.map(fn.group_texts, batched=True,fn_kwargs={'chunk_size': chunk_size})\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] \" my son, who was used to using a wood stool ( [MASK]'' tall with slick wood [MASK] ) fell climbing up [MASK] this because the top ( foot relocate ) [MASK] too small and it tipped on [MASK]! it's only 6'[MASK] wide on top spurs [MASK] [MASK] room khan clumsy [MASK] [MASK] to turn around on. [MASK] you push [MASK] in toward the toilet there is [MASK] left for the [MASK] to stand on. if you leave it out, [MASK] it takes up more room and the arc design is a waste. [MASK] down he also started to fall because it was such a narrow top. [MASK] feet [MASK] dangled as he'\n",
      "\n",
      "'>>> sat on the toilet - not [MASK] near the top of this 8 1 [MASK] 2'' tall stool. medieval is [MASK] as being 10 raging'tall ( actually 8 1 / 2'[MASK] ) 14'' long ( correct, but top surface is only [MASK] 1 [MASK] [MASK]'' ) and orthodox'' wide ( also correct but again [MASK] it is only 6'[MASK] wide on [MASK] ) the rubber feet are great for [MASK] - skid purposes, but that's the only positive thing [MASK] have to say about this. \" [SEP] [CLS] \" i was very disp piered [MASK] this product. [MASK] found [MASK] great that the containers'\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "samples = [lm_datasets['train'][i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "dd=data_collator(samples)\n",
    "for chunk in dd[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "downsampled_dataset = lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reload(fn)\n",
    "trainer = fn.train_mlm_model(model,adapter_name,data_collator,tokenizer, downsampled_dataset['train'],downsampled_dataset['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef8b0effb504d36931b395d685c2ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 21.19\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe779b2b9c854288bdbb2b783390846e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1944, 'grad_norm': 2.3381853103637695, 'learning_rate': 8.599999999999999e-06, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a507e1e2be4074af329a456a7cceaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0137174129486084, 'eval_runtime': 0.5211, 'eval_samples_per_second': 308.933, 'eval_steps_per_second': 11.513, 'epoch': 1.0}\n",
      "{'loss': 2.9801, 'grad_norm': 2.1476967334747314, 'learning_rate': 1.7199999999999998e-05, 'epoch': 1.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780a7bb607434763ade14521cde140c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5658199787139893, 'eval_runtime': 0.5047, 'eval_samples_per_second': 319.005, 'eval_steps_per_second': 11.888, 'epoch': 2.0}\n",
      "{'loss': 2.8199, 'grad_norm': 2.0252134799957275, 'learning_rate': 2.58e-05, 'epoch': 2.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33bebaefe97a47e48abbf1381f0ab448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.651716709136963, 'eval_runtime': 0.5038, 'eval_samples_per_second': 319.587, 'eval_steps_per_second': 11.91, 'epoch': 3.0}\n",
      "{'loss': 2.6522, 'grad_norm': 1.8795708417892456, 'learning_rate': 3.4399999999999996e-05, 'epoch': 3.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927dda91d0534ef6a579a31d889466d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.564641237258911, 'eval_runtime': 0.5147, 'eval_samples_per_second': 312.809, 'eval_steps_per_second': 11.657, 'epoch': 4.0}\n",
      "{'loss': 2.5686, 'grad_norm': 1.9459627866744995, 'learning_rate': 4.3e-05, 'epoch': 4.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66c1b8d6eb74d6681e93c68f537e837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.458320379257202, 'eval_runtime': 0.5135, 'eval_samples_per_second': 313.538, 'eval_steps_per_second': 11.685, 'epoch': 5.0}\n",
      "{'loss': 2.5256, 'grad_norm': 1.9190635681152344, 'learning_rate': 5.16e-05, 'epoch': 5.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03304d870fd7447594095491357ba26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4021127223968506, 'eval_runtime': 0.5061, 'eval_samples_per_second': 318.125, 'eval_steps_per_second': 11.856, 'epoch': 6.0}\n",
      "{'loss': 2.4984, 'grad_norm': 1.9794584512710571, 'learning_rate': 6.02e-05, 'epoch': 6.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ee06acc071492296e18f9af40cda0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.436417818069458, 'eval_runtime': 0.5176, 'eval_samples_per_second': 311.035, 'eval_steps_per_second': 11.591, 'epoch': 7.0}\n",
      "{'loss': 2.4138, 'grad_norm': 1.9649748802185059, 'learning_rate': 6.879999999999999e-05, 'epoch': 7.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ecc444bf6f46139bbd4941191f79a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.304912567138672, 'eval_runtime': 0.5236, 'eval_samples_per_second': 307.508, 'eval_steps_per_second': 11.46, 'epoch': 8.0}\n",
      "{'loss': 2.4155, 'grad_norm': 1.9653998613357544, 'learning_rate': 7.740000000000001e-05, 'epoch': 8.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b117c5f1c04da8aebbea076a31b4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3308374881744385, 'eval_runtime': 0.5272, 'eval_samples_per_second': 305.411, 'eval_steps_per_second': 11.382, 'epoch': 9.0}\n",
      "{'loss': 2.3634, 'grad_norm': 1.9336785078048706, 'learning_rate': 8.6e-05, 'epoch': 9.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ffab340d8f946fe8791487007d72dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.25753116607666, 'eval_runtime': 0.5034, 'eval_samples_per_second': 319.816, 'eval_steps_per_second': 11.919, 'epoch': 10.0}\n",
      "{'loss': 2.3317, 'grad_norm': 1.839006781578064, 'learning_rate': 9.46e-05, 'epoch': 10.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aae34eb810944ab8df2dd836fd789c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.307739019393921, 'eval_runtime': 0.5033, 'eval_samples_per_second': 319.873, 'eval_steps_per_second': 11.921, 'epoch': 11.0}\n",
      "{'loss': 2.3225, 'grad_norm': 1.9765613079071045, 'learning_rate': 9.578947368421052e-05, 'epoch': 11.73}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27182158bb243d8ae9c1cc7ad6cb97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2310848236083984, 'eval_runtime': 0.5122, 'eval_samples_per_second': 314.349, 'eval_steps_per_second': 11.715, 'epoch': 12.0}\n",
      "{'loss': 2.2946, 'grad_norm': 1.8529508113861084, 'learning_rate': 8.447368421052632e-05, 'epoch': 12.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc81cf3ccf64e87ba65760f6d774007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3229217529296875, 'eval_runtime': 0.5024, 'eval_samples_per_second': 320.458, 'eval_steps_per_second': 11.943, 'epoch': 13.0}\n",
      "{'loss': 2.24, 'grad_norm': 1.993794322013855, 'learning_rate': 7.315789473684212e-05, 'epoch': 13.68}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8a556b37894417879b8c4a22abba1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.102541446685791, 'eval_runtime': 0.5141, 'eval_samples_per_second': 313.153, 'eval_steps_per_second': 11.67, 'epoch': 14.0}\n",
      "{'loss': 2.2292, 'grad_norm': 2.0863871574401855, 'learning_rate': 6.18421052631579e-05, 'epoch': 14.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7eedc57a9f4bb0b71c60be596ab8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2705888748168945, 'eval_runtime': 0.5187, 'eval_samples_per_second': 310.399, 'eval_steps_per_second': 11.568, 'epoch': 15.0}\n",
      "{'loss': 2.2227, 'grad_norm': 1.8929237127304077, 'learning_rate': 5.052631578947369e-05, 'epoch': 15.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511ee68bf88546e9bc2b7631cf93afeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1772449016571045, 'eval_runtime': 0.508, 'eval_samples_per_second': 316.91, 'eval_steps_per_second': 11.81, 'epoch': 16.0}\n",
      "{'loss': 2.1973, 'grad_norm': 1.9152376651763916, 'learning_rate': 3.921052631578947e-05, 'epoch': 16.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86d65ca640e4be5b1bf71e86953149d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwriting existing adapter 'mlm_inv_baby'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2778496742248535, 'eval_runtime': 0.5184, 'eval_samples_per_second': 310.6, 'eval_steps_per_second': 11.575, 'epoch': 17.0}\n",
      "{'train_runtime': 169.8558, 'train_samples_per_second': 165.434, 'train_steps_per_second': 5.181, 'train_loss': 2.479313141521923, 'epoch': 17.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=748, training_loss=2.479313141521923, metrics={'train_runtime': 169.8558, 'train_samples_per_second': 165.434, 'train_steps_per_second': 5.181, 'train_loss': 2.479313141521923, 'epoch': 17.0})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65cbb35a6144e52890dc1a680aadffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 9.21\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config.config as config\n",
    "\n",
    "trainer.model.save_adapter(f\"{config.Config.ADAPTER_SAVE_PATH}/{adapter_name}\", adapter_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a report of mlm for goverment domain using whole genre as target and then splitt after tokenization with seed 42. I used computer metrix for preplexity and early stopping \n",
    "The results before:\n",
    ">>> Perplexity: 14.10\n",
    "\n",
    "The results after:\n",
    ">>> Perplexity: 4.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intial-experments-_CPDD38x-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
