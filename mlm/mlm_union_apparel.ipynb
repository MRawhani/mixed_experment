{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/guest/Desktop/projects/third-experiments/SDA_experiments/mlm', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages', '/home/guest/Desktop/projects/third-experiments/SDA_experiments/modules']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 02:28:30.701756: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-28 02:28:30.733639: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-28 02:28:31.207847: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from setup import setup_src_path\n",
    "print(setup_src_path())\n",
    "import data.processed as processed\n",
    "import config.config as config\n",
    "import utils.setup as setup\n",
    "import utils.functions as fn\n",
    "from importlib import reload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset with Unlabeled and Dev Splits:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence'],\n",
      "        num_rows: 1440\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['sentence'],\n",
      "        num_rows: 160\n",
      "    })\n",
      "})\n",
      "\n",
      "Test Target Dataset:\n",
      "Dataset({\n",
      "    features: ['sentence', 'label'],\n",
      "    num_rows: 400\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk,concatenate_datasets\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "adapter_name=\"mlm_union_apparel\"\n",
    "\n",
    "# Define paths to the CSV files\n",
    "# chose any file ends with category as target\n",
    "unlabeled_target_data_path = \"../../datasets/sa/baby_apparel/target_unlabelled.csv\"\n",
    "dev_target_data_path = \"../../datasets/sa/baby_apparel/dev_target.csv\"\n",
    "test_target_data_path = \"../../datasets/sa/baby_apparel/test_target.csv\"\n",
    "\n",
    "# Read the CSV files into DataFrames\n",
    "df_unlabeled_target = pd.read_csv(unlabeled_target_data_path)\n",
    "df_dev_target = pd.read_csv(dev_target_data_path)\n",
    "df_test_target = pd.read_csv(test_target_data_path)\n",
    "\n",
    "# Convert the DataFrames to dictionaries\n",
    "data_dict_unlabeled_target = df_unlabeled_target.to_dict(orient=\"records\")\n",
    "data_dict_dev_target = df_dev_target.to_dict(orient=\"records\")\n",
    "data_dict_test_target = df_test_target.to_dict(orient=\"records\")\n",
    "\n",
    "# Create Dataset objects from the dictionaries\n",
    "dataset_unlabeled_target = Dataset.from_dict({\n",
    "    \"sentence\": [record[\"sentence\"] for record in data_dict_unlabeled_target],\n",
    "    \n",
    "})\n",
    "\n",
    "dataset_dev_target = Dataset.from_dict({\n",
    "    \"sentence\": [record[\"sentence\"] for record in data_dict_dev_target],\n",
    "})\n",
    "\n",
    "dataset_test_target = Dataset.from_dict({\n",
    "    \"sentence\": [record[\"sentence\"] for record in data_dict_test_target],\n",
    "    \"label\": [record[\"label\"] for record in data_dict_test_target]\n",
    "})\n",
    "\n",
    "# Combine the unlabeled_target and dev_target datasets into a DatasetDict for training\n",
    "dataset_train = DatasetDict({\n",
    "    \"train\": dataset_unlabeled_target,\n",
    "    \"dev\": dataset_dev_target\n",
    "})\n",
    "\n",
    "# Print the datasets to verify\n",
    "print(\"Training Dataset with Unlabeled and Dev Splits:\")\n",
    "print(dataset_train)\n",
    "\n",
    "print(\"\\nTest Target Dataset:\")\n",
    "print(dataset_test_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '\"the presentation of the product is claer and attractive and the product is durable , comfortable and goodlooking\"'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(config)\n",
    "\n",
    "\n",
    "train_target = dataset_train\n",
    "test_target = dataset_test_target\n",
    "train_target['train'][399]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 109514298 || all params: 109514298 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "from adapters import AutoAdapterModel,init\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForMaskedLM\n",
    "\n",
    "mdlcfg = AutoConfig.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    " \n",
    ")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    ")\n",
    "init(model)\n",
    "reload(fn)\n",
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "mlm_union_apparel        union             7,682,688       7.055       1       1\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                               108,891,648     100.000               0\n",
      "================================================================================\n",
      "trainable params: 8274816 || all params: 117196986 || trainable%: 7.060604783812444\n"
     ]
    }
   ],
   "source": [
    "from adapters import ConfigUnion, LoRAConfig, PrefixTuningConfig, SeqBnConfig,SeqBnInvConfig,AdapterConfig,LoRAConfig\n",
    "\n",
    "union_config = ConfigUnion(\n",
    "    SeqBnInvConfig(reduction_factor=2),\n",
    "    LoRAConfig(r=8, alpha=16),\n",
    ")\n",
    "model.add_adapter(adapter_name, config=union_config)\n",
    "\n",
    "model.train_adapter([adapter_name])\n",
    "model.active_adapters = adapter_name\n",
    "print(model.adapter_summary())\n",
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ee33a9d937456290a643920d224816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f82c783d5ae45ffb9ee59f686085a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 1440\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 160\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "reload(processed)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.Config.TOKENIZER_NAME)\n",
    "\n",
    "tokenized_dataset= processed.tokenize_dataset(train_target,tokenizer)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'label'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n"
     ]
    }
   ],
   "source": [
    "reload(fn)\n",
    "# we might not need chunks, becasue it is simple sentences\n",
    "# padding tokens are going to be ignored in the collator 15%, and will be -100 in the lables\n",
    "chunk_size = 128\n",
    "# Slicing produces a list of lists for each feature\n",
    "tokenized_samples = tokenized_dataset['train'][444:470]\n",
    "\n",
    "results = fn.group_texts(tokenized_samples, chunk_size)\n",
    "for chunk in results[\"labels\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc5193efd284b1ca28ada705bdae701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "440\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1739e8e51d4ebda6ad9fd6f9362132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we group texts and chunk them\n",
    "lm_datasets = tokenized_dataset.map(fn.group_texts, batched=True,fn_kwargs={'chunk_size': chunk_size})\n",
    "len(lm_datasets['train']['labels'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] \" i was so disappointed in these [MASK] i [MASK] full - busted ( [MASK]dd ) [MASK] my nipples are sensitive and show through my bra and shirts all the time. i used a band - aid and it did a better job. these provided no help at all. and they really hurt taking them off \" [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n",
      "\n",
      "'>>> [CLS] \" this visor is square in shape [MASK] of oval, i have never seen a square vis [MASK] before. it looks very strange. also,wich is not comfortable as it is supposed [MASK] be, it is uncomfortable at the location where the sides hug to my head. i will not be wearing [MASK] \" [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "samples = [lm_datasets['train'][i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "dd=data_collator(samples)\n",
    "for chunk in dd[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "downsampled_dataset = lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages/accelerate/accelerator.py:479: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reload(fn)\n",
    "trainer = fn.train_mlm_model(model,adapter_name,data_collator,tokenizer, downsampled_dataset['train'],downsampled_dataset['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a297f073b9044d189cabf90895c7b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 19.37\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3173f01bbd440fa78ac9fdf0a6fd93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9682, 'grad_norm': 2.4999067783355713, 'learning_rate': 9e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6ce3e8f1844755914a9e86e3b53a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8222403526306152, 'eval_runtime': 1.1426, 'eval_samples_per_second': 140.028, 'eval_steps_per_second': 4.376, 'epoch': 1.0}\n",
      "{'loss': 2.794, 'grad_norm': 3.1240029335021973, 'learning_rate': 1.8e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ae09be04bd4430a812f7f7cfa5a9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7332921028137207, 'eval_runtime': 1.1456, 'eval_samples_per_second': 139.66, 'eval_steps_per_second': 4.364, 'epoch': 2.0}\n",
      "{'loss': 2.6125, 'grad_norm': 2.550335168838501, 'learning_rate': 2.7000000000000002e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0069c53113d47d48beff1919bd7de52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.536447763442993, 'eval_runtime': 1.1539, 'eval_samples_per_second': 138.659, 'eval_steps_per_second': 4.333, 'epoch': 3.0}\n",
      "{'loss': 2.5107, 'grad_norm': 2.6619153022766113, 'learning_rate': 3.6e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708315cb630d4c84b72c01e1cb0abf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4314918518066406, 'eval_runtime': 1.1613, 'eval_samples_per_second': 137.778, 'eval_steps_per_second': 4.306, 'epoch': 4.0}\n",
      "{'loss': 2.4386, 'grad_norm': 2.6156678199768066, 'learning_rate': 4.5e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8091583fc5a9491c840644c75b63e957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.46358323097229, 'eval_runtime': 1.1689, 'eval_samples_per_second': 136.882, 'eval_steps_per_second': 4.278, 'epoch': 5.0}\n",
      "{'loss': 2.3733, 'grad_norm': 2.371880292892456, 'learning_rate': 5.4000000000000005e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ed5067ec68485c843b7e1fa6af50b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2866897583007812, 'eval_runtime': 1.1619, 'eval_samples_per_second': 137.711, 'eval_steps_per_second': 4.303, 'epoch': 6.0}\n",
      "{'loss': 2.3238, 'grad_norm': 2.401660442352295, 'learning_rate': 6.3e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea6ef35f6fe403f8be1579c70322a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3104422092437744, 'eval_runtime': 1.167, 'eval_samples_per_second': 137.098, 'eval_steps_per_second': 4.284, 'epoch': 7.0}\n",
      "{'loss': 2.2857, 'grad_norm': 2.569953203201294, 'learning_rate': 7.2e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5299adec974d4262be2093ff3695945f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.361593246459961, 'eval_runtime': 1.1706, 'eval_samples_per_second': 136.678, 'eval_steps_per_second': 4.271, 'epoch': 8.0}\n",
      "{'loss': 2.2496, 'grad_norm': 2.1307733058929443, 'learning_rate': 8.1e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2d319da487413bb6aa71f1e6d65cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2774391174316406, 'eval_runtime': 1.1666, 'eval_samples_per_second': 137.147, 'eval_steps_per_second': 4.286, 'epoch': 9.0}\n",
      "{'loss': 2.2233, 'grad_norm': 2.658827066421509, 'learning_rate': 9e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fc49073dfa4a298c9a2928226f309f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2802023887634277, 'eval_runtime': 1.1674, 'eval_samples_per_second': 137.054, 'eval_steps_per_second': 4.283, 'epoch': 10.0}\n",
      "{'loss': 2.1928, 'grad_norm': 2.3998489379882812, 'learning_rate': 9.900000000000001e-05, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734e495a1af041d09e9eea4ecf56b1b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.185734987258911, 'eval_runtime': 1.1647, 'eval_samples_per_second': 137.38, 'eval_steps_per_second': 4.293, 'epoch': 11.0}\n",
      "{'loss': 2.1814, 'grad_norm': 2.105527639389038, 'learning_rate': 9e-05, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5956f9c5d741999dd110fe880f6847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.257655382156372, 'eval_runtime': 1.164, 'eval_samples_per_second': 137.453, 'eval_steps_per_second': 4.295, 'epoch': 12.0}\n",
      "{'loss': 2.1347, 'grad_norm': 2.0977439880371094, 'learning_rate': 7.875e-05, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe21702a57d6426ebf1e1191b0e22628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2382731437683105, 'eval_runtime': 1.1648, 'eval_samples_per_second': 137.359, 'eval_steps_per_second': 4.292, 'epoch': 13.0}\n",
      "{'loss': 2.0974, 'grad_norm': 2.2674667835235596, 'learning_rate': 6.750000000000001e-05, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87af3ff30da446cb8733f0db9398cbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1591708660125732, 'eval_runtime': 1.1665, 'eval_samples_per_second': 137.162, 'eval_steps_per_second': 4.286, 'epoch': 14.0}\n",
      "{'loss': 2.1468, 'grad_norm': 2.3875465393066406, 'learning_rate': 5.6250000000000005e-05, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c87a96f80cb4817b5c9c84b06195bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1516025066375732, 'eval_runtime': 1.1698, 'eval_samples_per_second': 136.78, 'eval_steps_per_second': 4.274, 'epoch': 15.0}\n",
      "{'loss': 2.0583, 'grad_norm': 2.241118907928467, 'learning_rate': 4.5e-05, 'epoch': 16.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75610b51622a48d88b9dfa4b59094ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2165400981903076, 'eval_runtime': 1.1704, 'eval_samples_per_second': 136.704, 'eval_steps_per_second': 4.272, 'epoch': 16.0}\n",
      "{'loss': 2.0517, 'grad_norm': 2.326260566711426, 'learning_rate': 3.375000000000001e-05, 'epoch': 17.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ecee5cc2c1428ba07727cabde733f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.160926103591919, 'eval_runtime': 1.1664, 'eval_samples_per_second': 137.178, 'eval_steps_per_second': 4.287, 'epoch': 17.0}\n",
      "{'loss': 2.0808, 'grad_norm': 2.4215691089630127, 'learning_rate': 2.25e-05, 'epoch': 18.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dcd35374b7f4fed82d0c7d6e8c5521c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0617897510528564, 'eval_runtime': 1.1701, 'eval_samples_per_second': 136.738, 'eval_steps_per_second': 4.273, 'epoch': 18.0}\n",
      "{'loss': 2.063, 'grad_norm': 2.393552303314209, 'learning_rate': 1.125e-05, 'epoch': 19.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df67b80b8b1740e28de38fc3e5110f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.17132830619812, 'eval_runtime': 1.1635, 'eval_samples_per_second': 137.515, 'eval_steps_per_second': 4.297, 'epoch': 19.0}\n",
      "{'loss': 1.9853, 'grad_norm': 2.7891573905944824, 'learning_rate': 0.0, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e15aef58f454bd98e858a0364ab5fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.062060832977295, 'eval_runtime': 1.1677, 'eval_samples_per_second': 137.024, 'eval_steps_per_second': 4.282, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwriting existing adapter 'mlm_union_apparel'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 519.5826, 'train_samples_per_second': 55.429, 'train_steps_per_second': 1.732, 'train_loss': 2.2885980902777776, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages/adapters/loading.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(weights_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=900, training_loss=2.2885980902777776, metrics={'train_runtime': 519.5826, 'train_samples_per_second': 55.429, 'train_steps_per_second': 1.732, 'train_loss': 2.2885980902777776, 'epoch': 20.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c176d5a8da497f984e3961fbe45d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 7.91\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2cb394439484c75b2124a84b9c15a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3abac8609445beb961c92ac9e35de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(processed)\n",
    "testtokenized_dataset= processed.tokenize_dataset(dataset_test_target,tokenizer)\n",
    "testtokenized_dataset\n",
    "# we group texts and chunk them\n",
    "test_dataset = testtokenized_dataset.map(fn.group_texts, batched=True,fn_kwargs={'chunk_size': chunk_size})\n",
    "test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33b236810fc494aacef4e171fe12808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity on the test dataset: 7.75\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Assuming `test_dataset` is already loaded and processed\n",
    "# Perform evaluation on the test dataset\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "# Extract the test loss from the metrics\n",
    "test_loss = test_results['eval_loss']\n",
    "\n",
    "# Calculate and print perplexity based on the test loss\n",
    "print(f\">>> Perplexity on the test dataset: {math.exp(test_loss):.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import config.config as config\n",
    "\n",
    "trainer.model.save_adapter(f\"{config.Config.ADAPTER_SAVE_PATH}/{adapter_name}\", adapter_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a report of mlm for goverment domain using whole genre as target and then splitt after tokenization with seed 42. I used computer metrix for preplexity and early stopping \n",
    "The results before:\n",
    ">>> Perplexity: 14.10\n",
    "\n",
    "The results after:\n",
    ">>> Perplexity: 4.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intial-experments-_CPDD38x-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
