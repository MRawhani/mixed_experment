{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/guest/Desktop/projects/third-experiments/SDA_experiments/mlm', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages', '/home/guest/Desktop/projects/third-experiments/SDA_experiments/modules']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 05:53:59.506858: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-25 05:53:59.691689: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-25 05:54:00.476871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from setup import setup_src_path\n",
    "print(setup_src_path())\n",
    "import data.processed as processed\n",
    "import config.config as config\n",
    "import utils.setup as setup\n",
    "import utils.functions as fn\n",
    "from importlib import reload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews in books: 37894\n",
      "Number of negative reviews in books: 38043\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "# Extract the dataset\n",
    "tar_path = '../../datasets/domain_sentiment_data.tar.gz'\n",
    "extract_path = '../../datasets/sorted_data_acl'\n",
    "\n",
    "# with tarfile.open(tar_path, 'r:gz') as tar:\n",
    "#     tar.extractall(path=extract_path)\n",
    "\n",
    "# Load the reviews\n",
    "def load_reviews(domain, label):\n",
    "    reviews = []\n",
    "    file_path = os.path.join(extract_path, domain, f'{label}.review')\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            reviews.append(line.strip())\n",
    "    return reviews\n",
    "\n",
    "# Example usage\n",
    "books_positive_reviews = load_reviews('books', 'positive')\n",
    "books_negative_reviews = load_reviews('books', 'negative')\n",
    "\n",
    "print(f'Number of positive reviews in books: {len(books_positive_reviews)}')\n",
    "print(f'Number of negative reviews in books: {len(books_negative_reviews)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4675ded2bd743308760e58d79fc1600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f926462d3caa4634a1d463adaf99c20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b07b553f0444f3b849c4e9298435ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbd75b9f7f448f8bb60700bffd0a8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8ca4b2e5c04822bab74e18ef833b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d96740f5604403aa7444f72e775790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/34741 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d2a6ab3410423fade80a2615279fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/13153 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f905ec4b4d4f159a23d3bc5266ed02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/16785 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: books\n",
      "  Class Balance: Counter({0: 1000, 1: 1000})\n",
      "  Total Samples: 2000\n",
      "  Sample Data:\n",
      "                                              review  label\n",
      "0  This book started out good but went downhill q...      0\n",
      "\n",
      "\n",
      "Domain: dvd\n",
      "  Class Balance: Counter({0: 1000, 1: 1000})\n",
      "  Total Samples: 2000\n",
      "  Sample Data:\n",
      "                                              review  label\n",
      "0  I picked this set up despite reservations (res...      0\n",
      "\n",
      "\n",
      "Domain: electronics\n",
      "  Class Balance: Counter({0: 1000, 1: 1000})\n",
      "  Total Samples: 2000\n",
      "  Sample Data:\n",
      "                                              review  label\n",
      "0  Great product. It's two in one. You have it in...      1\n",
      "\n",
      "\n",
      "Domain: kitchen_&_housewares\n",
      "  Class Balance: Counter({1: 1000, 0: 1000})\n",
      "  Total Samples: 2000\n",
      "  Sample Data:\n",
      "                                              review  label\n",
      "0  For ideal coffee using a French press is the b...      1\n",
      "\n",
      "\n",
      "Domain: books_unlabeled\n",
      "  Total Samples: 6000\n",
      "  Sample Data:\n",
      "                                              review\n",
      "0  First, let me deliver the highest possible pra...\n",
      "\n",
      "\n",
      "Domain: dvd_unlabeled\n",
      "  Total Samples: 34741\n",
      "  Sample Data:\n",
      "                                              review\n",
      "0  Excellent movie. The plot was unique as only S...\n",
      "\n",
      "\n",
      "Domain: electronics_unlabeled\n",
      "  Total Samples: 13153\n",
      "  Sample Data:\n",
      "                                              review\n",
      "0  Flakey, like nearly all of D-Link's wireless p...\n",
      "\n",
      "\n",
      "Domain: kitchen_&_housewares_unlabeled\n",
      "  Total Samples: 16785\n",
      "  Sample Data:\n",
      "                                              review\n",
      "0  These towels and wash cloths are very soft and...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import random\n",
    "import re\n",
    "from datasets import Dataset, DatasetDict\n",
    "from collections import Counter  # Ensure Counter is imported\n",
    "\n",
    "# Function to load and parse reviews from XML\n",
    "def load_reviews(domain, label):\n",
    "    reviews = []\n",
    "    file_path = os.path.join(extract_path, domain, f'{label}.review')\n",
    "    with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "        content = file.read()\n",
    "        reviews_xml = content.split('</review>')[:-1]  # Split the file by review end tag\n",
    "        for review_xml in reviews_xml:\n",
    "            review_xml += '</review>'  # Add the closing tag back\n",
    "            review_text_match = re.search(r'<review_text>(.*?)</review_text>', review_xml, re.DOTALL)\n",
    "            if review_text_match:\n",
    "                review_text = review_text_match.group(1).strip()\n",
    "                reviews.append(review_text)\n",
    "    return reviews\n",
    "\n",
    "# Function to load unlabeled reviews\n",
    "def load_unlabeled_reviews(domain):\n",
    "    reviews = []\n",
    "    file_path = os.path.join(extract_path, domain, 'unlabeled.review')\n",
    "    with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "        content = file.read()\n",
    "        reviews_xml = content.split('</review>')[:-1]  # Split the file by review end tag\n",
    "        for review_xml in reviews_xml:\n",
    "            review_xml += '</review>'  # Add the closing tag back\n",
    "            review_text_match = re.search(r'<review_text>(.*?)</review_text>', review_xml, re.DOTALL)\n",
    "            if review_text_match:\n",
    "                review_text = review_text_match.group(1).strip()\n",
    "                reviews.append(review_text)\n",
    "    return reviews\n",
    "\n",
    "# Merge, label, and shuffle reviews\n",
    "def get_labeled_reviews(domain):\n",
    "    positive_reviews = load_reviews(domain, 'positive')\n",
    "    negative_reviews = load_reviews(domain, 'negative')\n",
    "    reviews = [{'review': review, 'label': 1} for review in positive_reviews] + \\\n",
    "              [{'review': review, 'label': 0} for review in negative_reviews]\n",
    "    random.shuffle(reviews)\n",
    "    return reviews\n",
    "\n",
    "def get_unlabeled_reviews(domain):\n",
    "    unlabeled_reviews = load_unlabeled_reviews(domain)\n",
    "    reviews = [{'review': review} for review in unlabeled_reviews]\n",
    "    return reviews\n",
    "\n",
    "# Create DatasetDict object\n",
    "domains = ['books', 'dvd', 'electronics', 'kitchen_&_housewares']\n",
    "data_dict = {\n",
    "    domain: {\n",
    "        'labeled': get_labeled_reviews(domain),\n",
    "        'unlabeled': get_unlabeled_reviews(domain)\n",
    "    }\n",
    "    for domain in domains\n",
    "}\n",
    "\n",
    "# Convert to datasets.Dataset\n",
    "dataset_dict = {\n",
    "    domain: Dataset.from_dict({\n",
    "        'review': [entry['review'] for entry in data['labeled']],\n",
    "        'label': [entry['label'] for entry in data['labeled']]\n",
    "    })\n",
    "    for domain, data in data_dict.items()\n",
    "}\n",
    "unlabeled_dataset_dict = {\n",
    "    f\"{domain}_unlabeled\": Dataset.from_dict({\n",
    "        'review': [entry['review'] for entry in data['unlabeled']]\n",
    "    })\n",
    "    for domain, data in data_dict.items()\n",
    "}\n",
    "\n",
    "# Combine labeled and unlabeled datasets\n",
    "all_datasets = DatasetDict({**dataset_dict, **unlabeled_dataset_dict})\n",
    "\n",
    "# Save datasets to disk\n",
    "all_datasets.save_to_disk(f\"{config.Config.DATASETS_SAVE_PATH}/SDA\")\n",
    "\n",
    "# To load the datasets back from disk\n",
    "loaded_datasets = DatasetDict.load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/SDA\")\n",
    "\n",
    "# Verify the loaded datasets\n",
    "for domain, dataset in loaded_datasets.items():\n",
    "    print(f\"Domain: {domain}\")\n",
    "    if \"unlabeled\" not in domain:\n",
    "        balance = Counter(dataset['label'])\n",
    "        print(f\"  Class Balance: {balance}\")\n",
    "    print(f\"  Total Samples: {len(dataset)}\")\n",
    "    print(\"  Sample Data:\")\n",
    "    print(dataset.shuffle(seed=42).select(range(1)).to_pandas()[['review', 'label'] if 'unlabeled' not in domain else ['review']])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  review                                                                                                                                                                                                                                                                \n",
      "0  Excellent movie. The plot was unique as only S. King can make it, the acting was excellent thanks to the great casting and the photography, scenery and costumes excellent. In a word - 'gripping' from bigining to end.\\n\\nThe DVD itself was also excellent quality\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.colheader_justify', 'left')  # Align headers to the left\n",
    "books_unlabeled_sample = loaded_datasets['dvd_unlabeled'].shuffle(seed=42).select(range(1)).to_pandas()\n",
    "books_unlabeled_sample['review'] = books_unlabeled_sample['review'].str.strip()\n",
    "# Display the sample\n",
    "print(books_unlabeled_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1f2bedee7249999bf4976b4667f7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016301126c67418fbfb574d8ee825f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308d0d1f61c442d7ae115e6593742b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5eab3ccf3cb4476aaafb4a7b2bf5bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets.save_to_disk(f\"{config.Config.DATASETS_SAVE_PATH}/SDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    books: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    dvd: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    electronics: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    kitchen_&_housewares: Dataset({\n",
       "        features: ['review', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    books_unlabeled: Dataset({\n",
       "        features: ['review'],\n",
       "        num_rows: 6000\n",
       "    })\n",
       "    dvd_unlabeled: Dataset({\n",
       "        features: ['review'],\n",
       "        num_rows: 34741\n",
       "    })\n",
       "    electronics_unlabeled: Dataset({\n",
       "        features: ['review'],\n",
       "        num_rows: 13153\n",
       "    })\n",
       "    kitchen_&_housewares_unlabeled: Dataset({\n",
       "        features: ['review'],\n",
       "        num_rows: 16785\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk,concatenate_datasets\n",
    "\n",
    "\n",
    "adapter_name=\"SDA_mlm_inv_G\"\n",
    "dataset = load_from_disk(f\"{config.Config.DATASETS_SAVE_PATH}/SDA\")\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': [\"I've read a lot of the books in the series, and Hillerman is one of my favorite mystery writers, but I have to say this one fell way short of his other mysteries.  My main complaint is the presence of several plot gaps and inconsistencies not characteristic of the author--his well-crafted mysteries almost always hold water, but not this one.  I whole-heartedly recommend most of Hillerman's other Jim Chee/Joe Leaphorn novels, but if you want a good entrance into his captivating style and skill, this is not the book to pick up.\",\n",
       "  'When Peter S. Lynch speaks, wise investors will listen.  This book covers the famous fund manager\\'s career at the helm of Fidelity Magellan from 1977 to \\'90, and post career into \\'92.  It\\'s far more introspective than \"One Up On Wall Street\" and it was no doubt meant to be for this purpose.  For example, there isn\\'t nearly as much fundamental principles for stock picking outlined in this book as the former.  My belief is that the reader would do best by reading \"One Up On Wall Street\" first and follow up with this title, as its the newer of the two, regardless. \\n\\nPeter\\'s style of writing (with John Rothchild) is no-nonsense and easy to take in.  To my knowledge three books have been published by the duo and all three have been entertaining and never dry.  The reader can comfortably take in some very important stock-picking principles from one of the greats without feeling intimidated at any point.  I think this is a sign of a well written book that covers a topic that isn\\'t child\\'s play (unless you like playing with money).\\n\\nAnd although this book doesn\\'t cover nearly as much technical information as the first, it still offers a lot of tasty tidbits for stock pickers.  I made plenty of notes while reading \"Beating The Street\", and I\\'m confident that I\\'ll be well served by doing so.  Peter reiterates many of the guidelines he mentioned in his first best-seller, such as scrutinizing company earnings and the balance sheets, and he gives his wise opinion of picking bargain stocks that have lower P/Es than their growth rates.\\n\\nOverall, this title definitely deserves four stars, and his first book deserves at least five stars.  Lynch and Rothchild have authored several investing books that will stand the test of time. You\\'ll sleep better with your investment decisions by having these valuable classics in your collection.',\n",
       "  'Without question a book is needed to address the origin and history of late night television and Steve Allen\\'s pivitol role it. Sadly Ben Alba\\'s \"Inventing Late Night: Steve Allen and the Original \"Tonight Show\\'\\', is not that book. It is, largely, a poorly edited and self-contradicting pastiche of previously published memoirs by Allen himself combined with some excellent interviews with Allen\\'s TV contemporaries. These interviews could form the basis of an excellent book by the likes of biographers Scott Berg (Sam Goldwin) or Neal Gabler (Walter Winchle).\\nThe opening chapter, which addresses Allen\\'s dysfuntional up-bring, education and his early days in radio and TV sets the stage for the author\\'s failure to create a full-blooded, well-rounded analytical portrait of Allen and his work. Alba draws here, almost exclusively and certainly uncritically, from Allen\\'s memiors while combining these words with one quote from a childhood friend and two early reviews. Taking Allen and the reader\\'s one independent witness at face value, Allen had a rootless, violent and unstable childhood. Given these negative conditions Alba gives  no hint of how, why or even if, Allen really remained attached to his drunken and generally unstable mother and her equally troubled extended family. The author gives us two brief stories from Allen\\'s adulthood to demonstarte that the family ties endured. Actually, all the stories show is that Allen attended an uncle\\'s funeral and very briefly troted his mother out once on his Sunday night show. How did this dysfunctional world of Allen\\'s youth effect his two marriages and five sons? Why, after a childhood on the fringes of a perlious show business existance did Allen choose this same career field for himself? Alba doesn\\'t even pose such questions about the boy\\'s effects on the man. He just plows ahead in a haliographic haze. Throughout \"Inventing...\" Alba maintains this pattern of unquestioning acceptance Allen\\'s words. No other witnesses are called, no other points of view are examined. Steve tells a story; Alba accepts it and edits it into his text. Why not read Allen straight?',\n",
       "  \"I hold Martin's Song of Ice and Frie series in high regard; the man is a talented writer.  For adults. \\n\\n    The problem with this book is that it reads exactly like whay you'd expect a chlidren's book written by George R.R.Martin to read like.  By this I mean violent imagery and the occasional immolation of soon-to-be-dearly-departed-uncles.  (And as an uncle I object to this wanton anti-uncle setiment running rampant in children's literature!!!)\\n\\n   There seems to be no age group for this book.  The story isn't that engrossing, and a kid I'd feel comfortable buying a book for containing this level of violence would most likely want something more substanial.  Though for adults I strongly recommend Martin's other books over Mr. Pratchett, when it comes to books for kids about this age level I've gotta go with Pratchett's Wee Freemen over this.\\n\\nOr, for slightly younger kids, The Persistent Gappers of Firth.  Hell, eveybody loves the Gappers of Firth.\",\n",
       "  'For those looking to dig deeper into the nuances of the C language, this is an excellent book!  It has given me a better understanding of C that is helping me design better C code.  A must have'],\n",
       " 'label': [0, 1, 0, 0, 1]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['books'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase the text\n",
    "    text = text.replace('\\n', ' ').replace('\\\\n', ' ')  # Replace newline characters with spaces\n",
    "    text = re.sub(r'[/]', ' ', text)  # Replace slashes with spaces\n",
    "    text = re.sub(r'[^a-zA-Z0-9.,!?;:\\s]', '', text)  # Keep letters, numbers, and common punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    examples['review'] = [clean_text(review) for review in examples['review']]\n",
    "    return examples\n",
    "\n",
    "cleaned_datasets = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': [\"I've read a lot of the books in the series, and Hillerman is one of my favorite mystery writers, but I have to say this one fell way short of his other mysteries.  My main complaint is the presence of several plot gaps and inconsistencies not characteristic of the author--his well-crafted mysteries almost always hold water, but not this one.  I whole-heartedly recommend most of Hillerman's other Jim Chee/Joe Leaphorn novels, but if you want a good entrance into his captivating style and skill, this is not the book to pick up.\",\n",
       "  'When Peter S. Lynch speaks, wise investors will listen.  This book covers the famous fund manager\\'s career at the helm of Fidelity Magellan from 1977 to \\'90, and post career into \\'92.  It\\'s far more introspective than \"One Up On Wall Street\" and it was no doubt meant to be for this purpose.  For example, there isn\\'t nearly as much fundamental principles for stock picking outlined in this book as the former.  My belief is that the reader would do best by reading \"One Up On Wall Street\" first and follow up with this title, as its the newer of the two, regardless. \\n\\nPeter\\'s style of writing (with John Rothchild) is no-nonsense and easy to take in.  To my knowledge three books have been published by the duo and all three have been entertaining and never dry.  The reader can comfortably take in some very important stock-picking principles from one of the greats without feeling intimidated at any point.  I think this is a sign of a well written book that covers a topic that isn\\'t child\\'s play (unless you like playing with money).\\n\\nAnd although this book doesn\\'t cover nearly as much technical information as the first, it still offers a lot of tasty tidbits for stock pickers.  I made plenty of notes while reading \"Beating The Street\", and I\\'m confident that I\\'ll be well served by doing so.  Peter reiterates many of the guidelines he mentioned in his first best-seller, such as scrutinizing company earnings and the balance sheets, and he gives his wise opinion of picking bargain stocks that have lower P/Es than their growth rates.\\n\\nOverall, this title definitely deserves four stars, and his first book deserves at least five stars.  Lynch and Rothchild have authored several investing books that will stand the test of time. You\\'ll sleep better with your investment decisions by having these valuable classics in your collection.',\n",
       "  'Without question a book is needed to address the origin and history of late night television and Steve Allen\\'s pivitol role it. Sadly Ben Alba\\'s \"Inventing Late Night: Steve Allen and the Original \"Tonight Show\\'\\', is not that book. It is, largely, a poorly edited and self-contradicting pastiche of previously published memoirs by Allen himself combined with some excellent interviews with Allen\\'s TV contemporaries. These interviews could form the basis of an excellent book by the likes of biographers Scott Berg (Sam Goldwin) or Neal Gabler (Walter Winchle).\\nThe opening chapter, which addresses Allen\\'s dysfuntional up-bring, education and his early days in radio and TV sets the stage for the author\\'s failure to create a full-blooded, well-rounded analytical portrait of Allen and his work. Alba draws here, almost exclusively and certainly uncritically, from Allen\\'s memiors while combining these words with one quote from a childhood friend and two early reviews. Taking Allen and the reader\\'s one independent witness at face value, Allen had a rootless, violent and unstable childhood. Given these negative conditions Alba gives  no hint of how, why or even if, Allen really remained attached to his drunken and generally unstable mother and her equally troubled extended family. The author gives us two brief stories from Allen\\'s adulthood to demonstarte that the family ties endured. Actually, all the stories show is that Allen attended an uncle\\'s funeral and very briefly troted his mother out once on his Sunday night show. How did this dysfunctional world of Allen\\'s youth effect his two marriages and five sons? Why, after a childhood on the fringes of a perlious show business existance did Allen choose this same career field for himself? Alba doesn\\'t even pose such questions about the boy\\'s effects on the man. He just plows ahead in a haliographic haze. Throughout \"Inventing...\" Alba maintains this pattern of unquestioning acceptance Allen\\'s words. No other witnesses are called, no other points of view are examined. Steve tells a story; Alba accepts it and edits it into his text. Why not read Allen straight?',\n",
       "  \"I hold Martin's Song of Ice and Frie series in high regard; the man is a talented writer.  For adults. \\n\\n    The problem with this book is that it reads exactly like whay you'd expect a chlidren's book written by George R.R.Martin to read like.  By this I mean violent imagery and the occasional immolation of soon-to-be-dearly-departed-uncles.  (And as an uncle I object to this wanton anti-uncle setiment running rampant in children's literature!!!)\\n\\n   There seems to be no age group for this book.  The story isn't that engrossing, and a kid I'd feel comfortable buying a book for containing this level of violence would most likely want something more substanial.  Though for adults I strongly recommend Martin's other books over Mr. Pratchett, when it comes to books for kids about this age level I've gotta go with Pratchett's Wee Freemen over this.\\n\\nOr, for slightly younger kids, The Persistent Gappers of Firth.  Hell, eveybody loves the Gappers of Firth.\",\n",
       "  'For those looking to dig deeper into the nuances of the C language, this is an excellent book!  It has given me a better understanding of C that is helping me design better C code.  A must have'],\n",
       " 'label': [0, 1, 0, 0, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['books'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': ['ive read a lot of the books in the series, and hillerman is one of my favorite mystery writers, but i have to say this one fell way short of his other mysteries. my main complaint is the presence of several plot gaps and inconsistencies not characteristic of the authorhis wellcrafted mysteries almost always hold water, but not this one. i wholeheartedly recommend most of hillermans other jim chee joe leaphorn novels, but if you want a good entrance into his captivating style and skill, this is not the book to pick up.',\n",
       "  'when peter s. lynch speaks, wise investors will listen. this book covers the famous fund managers career at the helm of fidelity magellan from 1977 to 90, and post career into 92. its far more introspective than one up on wall street and it was no doubt meant to be for this purpose. for example, there isnt nearly as much fundamental principles for stock picking outlined in this book as the former. my belief is that the reader would do best by reading one up on wall street first and follow up with this title, as its the newer of the two, regardless. peters style of writing with john rothchild is nononsense and easy to take in. to my knowledge three books have been published by the duo and all three have been entertaining and never dry. the reader can comfortably take in some very important stockpicking principles from one of the greats without feeling intimidated at any point. i think this is a sign of a well written book that covers a topic that isnt childs play unless you like playing with money. and although this book doesnt cover nearly as much technical information as the first, it still offers a lot of tasty tidbits for stock pickers. i made plenty of notes while reading beating the street, and im confident that ill be well served by doing so. peter reiterates many of the guidelines he mentioned in his first bestseller, such as scrutinizing company earnings and the balance sheets, and he gives his wise opinion of picking bargain stocks that have lower p es than their growth rates. overall, this title definitely deserves four stars, and his first book deserves at least five stars. lynch and rothchild have authored several investing books that will stand the test of time. youll sleep better with your investment decisions by having these valuable classics in your collection.',\n",
       "  'without question a book is needed to address the origin and history of late night television and steve allens pivitol role it. sadly ben albas inventing late night: steve allen and the original tonight show, is not that book. it is, largely, a poorly edited and selfcontradicting pastiche of previously published memoirs by allen himself combined with some excellent interviews with allens tv contemporaries. these interviews could form the basis of an excellent book by the likes of biographers scott berg sam goldwin or neal gabler walter winchle. the opening chapter, which addresses allens dysfuntional upbring, education and his early days in radio and tv sets the stage for the authors failure to create a fullblooded, wellrounded analytical portrait of allen and his work. alba draws here, almost exclusively and certainly uncritically, from allens memiors while combining these words with one quote from a childhood friend and two early reviews. taking allen and the readers one independent witness at face value, allen had a rootless, violent and unstable childhood. given these negative conditions alba gives no hint of how, why or even if, allen really remained attached to his drunken and generally unstable mother and her equally troubled extended family. the author gives us two brief stories from allens adulthood to demonstarte that the family ties endured. actually, all the stories show is that allen attended an uncles funeral and very briefly troted his mother out once on his sunday night show. how did this dysfunctional world of allens youth effect his two marriages and five sons? why, after a childhood on the fringes of a perlious show business existance did allen choose this same career field for himself? alba doesnt even pose such questions about the boys effects on the man. he just plows ahead in a haliographic haze. throughout inventing... alba maintains this pattern of unquestioning acceptance allens words. no other witnesses are called, no other points of view are examined. steve tells a story; alba accepts it and edits it into his text. why not read allen straight?',\n",
       "  'i hold martins song of ice and frie series in high regard; the man is a talented writer. for adults. the problem with this book is that it reads exactly like whay youd expect a chlidrens book written by george r.r.martin to read like. by this i mean violent imagery and the occasional immolation of soontobedearlydeparteduncles. and as an uncle i object to this wanton antiuncle setiment running rampant in childrens literature!!! there seems to be no age group for this book. the story isnt that engrossing, and a kid id feel comfortable buying a book for containing this level of violence would most likely want something more substanial. though for adults i strongly recommend martins other books over mr. pratchett, when it comes to books for kids about this age level ive gotta go with pratchetts wee freemen over this. or, for slightly younger kids, the persistent gappers of firth. hell, eveybody loves the gappers of firth.',\n",
       "  'for those looking to dig deeper into the nuances of the c language, this is an excellent book! it has given me a better understanding of c that is helping me design better c code. a must have'],\n",
       " 'label': [0, 1, 0, 0, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_datasets['books'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0028c5ca32b4535807184d211a992b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79928c6cd95b4668ae93e2aae72da295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36cd1dcdb20e4bf59fca5169756221d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a01cbb7d283496aaf1dc39f17e05396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f19e14d56a449a9ee05e9efc73de9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4575243716b948feb7738a753168ebd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/34741 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf94a4393bf4bfe80ec991244fb44bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/13153 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f65b8059f054a45a7aca1ca08081293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/16785 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleaned_datasets.save_to_disk(f\"{config.Config.DATASETS_SAVE_PATH}/SDA_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'i was looking for a mouse to use with an hp livestrong laptop. i liked the size of the mouse, as well as the price. positive reviews made me decide to give it a try. ive had the mouse for two months now, and so far it has been working well. the only complaint that i have: it tends to lose bluetooth connection randomly. sometime i have to search for it using search for devices in range function on my laptop. on the positive side, i like its size and feel i wouldnt want to use it all the time but for a laptop its great. it comes with a usb charger and a storage bag. great part is that is doesnt need batteries and you can use it while its charging. you would need bluetooth to use it make sure you have it; otherwise, buy a wireless mouse. it works pretty precisely much better than a wireless dell mouse; it doesnt skip at all. installation was easy, but took me a few minutes to figure it out because it was my first bluetooth device that i was connecting to the laptop. overall, i would recommend this mouse'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(config)\n",
    "\n",
    "    \n",
    "filtered_target = cleaned_datasets['electronics'].shuffle(seed=42)\n",
    "unlabled_filtered_target = cleaned_datasets['electronics_unlabeled'].shuffle(seed=42)\n",
    "#filtered_target = shuffled_filtered_target.train_test_split(test_size=0.1)\n",
    "\n",
    "unlabled_filtered_target[4]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 109514298 || all params: 109514298 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "from adapters import AutoAdapterModel,init\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForMaskedLM\n",
    "\n",
    "mdlcfg = AutoConfig.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    " \n",
    ")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    config.Config.MODEL_NAME,\n",
    ")\n",
    "init(model)\n",
    "reload(fn)\n",
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Name                     Architecture         #Param      %Param  Active   Train\n",
      "--------------------------------------------------------------------------------\n",
      "SDA_mlm_inv_G            bottleneck        7,387,776       6.785       1       1\n",
      "--------------------------------------------------------------------------------\n",
      "Full model                               108,891,648     100.000               0\n",
      "================================================================================\n",
      "trainable params: 7979904 || all params: 116902074 || trainable%: 6.82614407679371\n"
     ]
    }
   ],
   "source": [
    "from adapters import ConfigUnion, LoRAConfig, PrefixTuningConfig, SeqBnConfig,SeqBnInvConfig,AdapterConfig,LoRAConfig\n",
    "\n",
    "\n",
    "adapter_config = SeqBnInvConfig(reduction_factor=2)\n",
    "\n",
    "model.add_adapter(adapter_name, config=adapter_config)\n",
    "\n",
    "model.train_adapter([adapter_name])\n",
    "model.active_adapters = adapter_name\n",
    "print(model.adapter_summary())\n",
    "fn.print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def count_words(dataset):\n",
    "    total_premise_words = 0\n",
    "    total_hypothesis_words = 0\n",
    "\n",
    "    # Iterate through each record in the dataset\n",
    "    for entry in dataset:\n",
    "        # Split the 'premise' and 'hypothesis' fields on spaces to count words\n",
    "        premise_words = entry['review'].split()\n",
    "\n",
    "        # Sum up the word counts\n",
    "        total_premise_words += len(premise_words)\n",
    "\n",
    "    return total_premise_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1439083"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(unlabled_filtered_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdfc5e1e7534452bf00fd1b50dcb1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13153 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "    num_rows: 13153\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "reload(processed)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.Config.TOKENIZER_NAME)\n",
    "\n",
    "def tokenize_dataset(data,tokenizer):\n",
    "    def tokenize_function(examples):\n",
    "        result = tokenizer(examples['review']) # no trunccation or padding cuz it is mlm\n",
    "        if tokenizer.is_fast:\n",
    "            result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "        return result\n",
    "\n",
    "\n",
    "    # Use batched=True to activate fast multithreading!\n",
    "    tokenized_datasets = data.map(\n",
    "        tokenize_function, batched=True, \n",
    "    )\n",
    "    tokenized_datasets = tokenized_datasets.remove_columns(['review'])\n",
    "\n",
    "    return tokenized_datasets\n",
    "\n",
    "tokenized_dataset= tokenize_dataset(unlabled_filtered_target,tokenizer)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 512'\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 512\n",
    "# Slicing produces a list of lists for each feature\n",
    "tokenized_samples = tokenized_dataset[444:470]\n",
    "\n",
    "results = fn.group_texts(tokenized_samples, chunk_size)\n",
    "for chunk in results[\"labels\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56240c8ea094fa2960c31f191c31e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13153 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "    num_rows: 3411\n",
       "})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we group texts and chunk them\n",
    "lm_datasets = tokenized_dataset.map(fn.group_texts, batched=True,fn_kwargs={'chunk_size': chunk_size})\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] flakey [MASK] like nearly all of dlinks [MASK] products. some days [MASK] works, connecting [MASK] to the dlink wpapsk [MASK]r i have, indy sometimes it wont connect at all. the 100mb [MASK] wired ethernet always works, [MASK], and works very well [MASK] a nice wired camera [MASK] that [MASK] will do wireless as well [SEP] [CLS] disappointing [MASK]. frequent reinstall necessary because it loses its linking id patriots more trouble [MASK] it is worth. i went back to cords [SEP] [CLS] i [MASK] 2 of the cdmavica [MASK] [MASK] the cd [MASK]0 uses these disks [MASK] with no problems. however with the cd500, about 2 3 [MASK] the disks have problems [MASK] i know it is not my camera causing this problem, i know several people with the same camera that have the same problem. if [MASK] have a cd500, [MASK] the [MASK] [MASK] [MASK] [MASK], i [MASK] not had a problem with any of them. [SEP] [CLS] crosses 1 gb card took all [MASK] pictures on a trip to hawaii, over [MASK] [SEP] [CLS] [MASK] was looking for a mouse [MASK] use [MASK] an hp livestrong laptop [MASK] i liked the size [MASK] the [MASK], as well as the price. [MASK] reviews made me decide to give it a try. iv [MASK] had the mouse for two months now, so far [MASK] has been working well. the only complaint that i have : it [MASK] to lose bluetooth connection randomly. sometime [MASK] have to search for it using search for devices in range [MASK] on my laptop. on the positive side, i like its [MASK] and feel [MASK] wouldnt want to use it all the [MASK] but [MASK] [MASK] laptop its great. it comes with a usb charger and a storage bag. great part is that is doesnt need [MASK] and [MASK] can use it while its [MASK]. you would need bluetooth to use it make sure you have it ; otherwise, buy a wireless mouse [MASK] it [MASK] [MASK] precisely much [MASK] than a [MASK] dell mouse ; it doesnt [MASK] at all. installation was easy, but took me a few minutes [MASK] figure it out because it was [MASK] first bluetooth device that i was connecting to the laptop. overall [MASK] i would recommend this mouse [SEP] [CLS] i purchased this monitor because of budgetary concerns. this item was the most inexpensive 17 inch monitor available to me at the time i [MASK] the purchase. my overall experience with [MASK] monitor was very poor. when [MASK] screen wasnt [MASK] or glitching the overall picture quality attempting poor to [MASK] [MASK] ive viewed numerous different monitor models since im a college'\n",
      "\n",
      "'>>> student and this particular monitor had as [MASK] of picture quality as any ive seen [MASK] [MASK] week out of the box and i began to see slight contraction [MASK] of the screen from time to time, [MASK] more frequent each day. display glit [MASK] and flashes also occurred [MASK] i [MASK] tell this was a quo [MASK] ; cheapquot ; monitor [MASK] soon as i set it up. i sent it back and now will search for a better quality monitor. id stay away from this brand, that is, if [MASK] ever come across it again. 3g technologies? searches across the net come up empty with these guys. two thumbs down [SEP] [CLS] i [MASK] this device [MASK] a christmas present last year. [MASK] [MASK] my first and i didnt have [MASK] clue about mp3. i have not had a [MASK] with this device [MASK] all [MASK] 60 ; br 62 ; 60 ; br 62 ; things i liked : 60 ; br 62 ; 60 ; br 62 ; easy to [MASK]. i downloaded through window medianever an issue. [MASK] ; br 62 ; 60 ; br 62 ; small and durable. i have dropped [MASK] device a [MASK] times [MASK] 60 ; br [MASK] ; 60 [MASK] 62 ; great soundif you use other head [MASK] than provided [MASK] 60 ; br 62 [MASK] 60 ; [MASK] 62 [MASK] only took a aa battery [MASK] 60 ; br 62 ; 60 ; br 62 ; things i [MASK] would happen : [MASK] ; br [MASK] ; 60 ; br 62 ; better headphones [MASK] ; br 62 ; a display60 ; [MASK] 62 ; ability to [MASK] [MASK] order [MASK] songs [MASK] transfer60 ; br 62 ; 60 ; br 62 ; otherwise [MASK] i have [MASK] no issues. i will be purchasing this item for [MASK] 14 [MASK] old daughter [SEP] [CLS] i got [MASK] keyset and the zboard for [MASK] boyfriend, and hes even more addicted to the computer. he says [MASK] so [MASK] easier to use, and all the buttons are right at your fingertips, rather than searching on the key [MASK]. a great christmas present [MASK] [MASK] fellow [MASK]s [SEP] [CLS] [MASK] keyboard blooms great. it has [MASK] comfortable typing positions, [MASK] the special function keys are [MASK] great [SEP] [CLS] does [MASK] it should ; well [MASK]stru [MASK]. sheng recommend for anyone who needs [MASK] length and prefers not to daisychain a bunch [unused901] [MASK] cables. should get better performance with this [MASK] [MASK] its a [MASK] length cable. [SEP] [CLS] [MASK] recieved the dvd [MASK] a timely fashion and it was in perfect working condition [SEP] [CLS] i needed a financial calculator [MASK] i had received a lot of good feedback from 12'\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "samples = [lm_datasets[i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "dd=data_collator(samples)\n",
    "for chunk in dd[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 3069\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 342\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "downsampled_dataset = lm_datasets.train_test_split(\n",
    "    test_size=0.1, seed=42\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/guest/.cache/pypoetry/virtualenvs/third-experments-xuKQSur9-py3.8/lib/python3.8/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reload(fn)\n",
    "trainer = fn.train_mlm_model(model,adapter_name,data_collator,tokenizer, downsampled_dataset['train'],downsampled_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5ae2eeed274242a7bc2def14bf1465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 23.34\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a91c05929545c399cc71b6c40f7ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1794, 'grad_norm': 1.1464124917984009, 'learning_rate': 1.9e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce30f87313c94dcbace299f8c09da6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8596105575561523, 'eval_runtime': 2.3706, 'eval_samples_per_second': 144.266, 'eval_steps_per_second': 4.64, 'epoch': 1.0}\n",
      "{'loss': 2.9097, 'grad_norm': 1.1410419940948486, 'learning_rate': 3.8e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a9d8523b214fc897a1a5ca02147420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6724538803100586, 'eval_runtime': 2.4324, 'eval_samples_per_second': 140.6, 'eval_steps_per_second': 4.522, 'epoch': 2.0}\n",
      "{'loss': 2.7846, 'grad_norm': 1.0846699476242065, 'learning_rate': 5.6999999999999996e-05, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649abd7f4e274ff6b4a8bc1cd06f01a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.591243267059326, 'eval_runtime': 2.3739, 'eval_samples_per_second': 144.067, 'eval_steps_per_second': 4.634, 'epoch': 3.0}\n",
      "{'loss': 2.6962, 'grad_norm': 1.0342456102371216, 'learning_rate': 7.6e-05, 'epoch': 3.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248b407d82a34e0088c73d230c933a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.538973331451416, 'eval_runtime': 2.3612, 'eval_samples_per_second': 144.843, 'eval_steps_per_second': 4.659, 'epoch': 4.0}\n",
      "{'loss': 2.629, 'grad_norm': 1.0543403625488281, 'learning_rate': 9.5e-05, 'epoch': 4.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b146f5f3fcc425cb7648aa3c7d2af8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.480184316635132, 'eval_runtime': 2.3849, 'eval_samples_per_second': 143.4, 'eval_steps_per_second': 4.612, 'epoch': 5.0}\n",
      "{'loss': 2.5876, 'grad_norm': 1.0973327159881592, 'learning_rate': 9.507042253521127e-05, 'epoch': 5.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185fca5b3b244a7f926b61207fb5c90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.450483798980713, 'eval_runtime': 4.5595, 'eval_samples_per_second': 75.009, 'eval_steps_per_second': 2.413, 'epoch': 6.0}\n",
      "{'loss': 2.5443, 'grad_norm': 1.0224871635437012, 'learning_rate': 8.838028169014085e-05, 'epoch': 6.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9652c04325e64698afff49a642fca8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4311764240264893, 'eval_runtime': 4.5302, 'eval_samples_per_second': 75.493, 'eval_steps_per_second': 2.428, 'epoch': 7.0}\n",
      "{'loss': 2.5077, 'grad_norm': 1.0707277059555054, 'learning_rate': 8.169014084507043e-05, 'epoch': 7.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaea968106f14d99aac420821bb4802c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4208452701568604, 'eval_runtime': 4.5548, 'eval_samples_per_second': 75.086, 'eval_steps_per_second': 2.415, 'epoch': 8.0}\n",
      "{'loss': 2.4774, 'grad_norm': 1.041139006614685, 'learning_rate': 7.500000000000001e-05, 'epoch': 8.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38861640898b4f02b0ecf83b70e06df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.381580114364624, 'eval_runtime': 4.5617, 'eval_samples_per_second': 74.972, 'eval_steps_per_second': 2.411, 'epoch': 9.0}\n",
      "{'loss': 2.4684, 'grad_norm': 0.9959837198257446, 'learning_rate': 6.830985915492957e-05, 'epoch': 9.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d4763393204b5b9f2a60a6b24b4cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3653812408447266, 'eval_runtime': 4.5881, 'eval_samples_per_second': 74.54, 'eval_steps_per_second': 2.398, 'epoch': 10.0}\n",
      "{'loss': 2.4383, 'grad_norm': 1.0089167356491089, 'learning_rate': 6.161971830985915e-05, 'epoch': 10.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bc128d828f442e92af18ffe59586da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3410661220550537, 'eval_runtime': 4.5934, 'eval_samples_per_second': 74.455, 'eval_steps_per_second': 2.395, 'epoch': 11.0}\n",
      "{'loss': 2.4248, 'grad_norm': 1.0159035921096802, 'learning_rate': 5.492957746478874e-05, 'epoch': 11.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ee48bd5d93430ab869f29d4cd303be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3126962184906006, 'eval_runtime': 4.5754, 'eval_samples_per_second': 74.747, 'eval_steps_per_second': 2.404, 'epoch': 12.0}\n",
      "{'loss': 2.4205, 'grad_norm': 1.0326164960861206, 'learning_rate': 4.8239436619718316e-05, 'epoch': 12.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56833dfe0fa84576a7a08213f54a9431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3179759979248047, 'eval_runtime': 4.5796, 'eval_samples_per_second': 74.679, 'eval_steps_per_second': 2.402, 'epoch': 13.0}\n",
      "{'loss': 2.4029, 'grad_norm': 1.0660465955734253, 'learning_rate': 4.154929577464789e-05, 'epoch': 13.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e29875c6b84318b8a79102752636c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3129868507385254, 'eval_runtime': 4.5264, 'eval_samples_per_second': 75.557, 'eval_steps_per_second': 2.43, 'epoch': 14.0}\n",
      "{'loss': 2.3856, 'grad_norm': 1.1251251697540283, 'learning_rate': 3.485915492957747e-05, 'epoch': 14.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0a71378d9b471ea70fe5904e07ce99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3003737926483154, 'eval_runtime': 4.6031, 'eval_samples_per_second': 74.297, 'eval_steps_per_second': 2.39, 'epoch': 15.0}\n",
      "{'loss': 2.3793, 'grad_norm': 1.0394067764282227, 'learning_rate': 2.8169014084507046e-05, 'epoch': 15.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f8f450282541d2b593052b9a1418de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.327202796936035, 'eval_runtime': 4.538, 'eval_samples_per_second': 75.363, 'eval_steps_per_second': 2.424, 'epoch': 16.0}\n",
      "{'loss': 2.376, 'grad_norm': 1.035460114479065, 'learning_rate': 2.147887323943662e-05, 'epoch': 16.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580038a5f8ff42b8b90704638f4a801e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2881722450256348, 'eval_runtime': 4.5348, 'eval_samples_per_second': 75.417, 'eval_steps_per_second': 2.426, 'epoch': 17.0}\n",
      "{'loss': 2.3807, 'grad_norm': 1.0614811182022095, 'learning_rate': 1.4788732394366198e-05, 'epoch': 17.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476fbd95e8684b96bd5d720a2610487a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2897469997406006, 'eval_runtime': 4.5513, 'eval_samples_per_second': 75.143, 'eval_steps_per_second': 2.417, 'epoch': 18.0}\n",
      "{'loss': 2.3631, 'grad_norm': 1.0209087133407593, 'learning_rate': 8.098591549295775e-06, 'epoch': 18.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcc182e20e04971891b9d9c2974bd94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.277920961380005, 'eval_runtime': 4.5551, 'eval_samples_per_second': 75.081, 'eval_steps_per_second': 2.415, 'epoch': 19.0}\n",
      "{'loss': 2.355, 'grad_norm': 1.0398510694503784, 'learning_rate': 1.4084507042253521e-06, 'epoch': 19.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2aad515d0dc4bd2923cced45570ee84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2944138050079346, 'eval_runtime': 4.5377, 'eval_samples_per_second': 75.368, 'eval_steps_per_second': 2.424, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwriting existing adapter 'SDA_mlm_inv_G'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1783.2134, 'train_samples_per_second': 34.421, 'train_steps_per_second': 1.077, 'train_loss': 2.5333909412225086, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1920, training_loss=2.5333909412225086, metrics={'train_runtime': 1783.2134, 'train_samples_per_second': 34.421, 'train_steps_per_second': 1.077, 'train_loss': 2.5333909412225086, 'epoch': 20.0})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c684b478b9774d039e547207f0db1442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 9.76\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import config.config as config\n",
    "\n",
    "trainer.model.save_adapter(f\"{config.Config.ADAPTER_SAVE_PATH}/{adapter_name}\", adapter_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a report of mlm for goverment domain using whole genre as target and then splitt after tokenization with seed 42. I used computer metrix for preplexity and early stopping \n",
    "The results before:\n",
    ">>> Perplexity: 16.32\n",
    "\n",
    "The results after:\n",
    ">>> Perplexity: 4.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intial-experments-_CPDD38x-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
